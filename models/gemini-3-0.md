# Gemini 3.0

> A solid front-end engineer with strong multimodal capabilities. Best inside AntiGravity.

---

## Overview

| Attribute | Assessment |
|-----------|------------|
| **Best for** | Front-end design, generating images/assets, multimodal tasks |
| **Avoid for** | General-purpose coding, anything outside its sweet spot |
| **Context retention** | Adequate |
| **Personality** | Quirky (not in a charming way), confusing reasoning |
| **Overall rating** | ⭐⭐⭐ |

---

## Strengths

**Front-End Engineering**
Gemini 3.0 is a genuinely solid front-end engineer. It's clearly been trained on strong design principles—the output tends to be clean, well-structured, and visually coherent.

**Design Aesthetic**
Like GPT 5.X, Gemini produces designs that are more brutal, more subtle—less "AI smell" than Claude. If you care about refined visual output, Gemini delivers.

**Multimodality & Asset Generation**
This is where Gemini shines. I use it specifically for generating assets, leveraging its ability to call image generation models (like NanoBanana Pro) directly in context.

**AntiGravity Integration**
Gemini works best inside AntiGravity (Google's code editor/IDE). The integration lets you generate assets directly into your repo, which is a workflow I haven't replicated with other models.

---

## Weaknesses

**Not a Generalist**
Gemini is not my first choice for anything outside front-end and asset generation. It doesn't have the all-around capability of Opus or the analytical depth of GPT 5.1.

**Quirky Personality**
The personality is... weird. Not in a charming or fun way—just odd. It doesn't feel like a natural thought partner.

**Confusing Reasoning**
If you read Gemini's reasoning traces, it sounds confused constantly. Circular logic, strange metacognition patterns. It somehow arrives at good outputs despite seemingly being lost in its own head.

**Pro tip**: Don't read the reasoning. Just look at the output.

---

## Personality

Quirky in a way that's hard to pin down. Not confrontational like GPT 5.2, not eager like Claude—just... off. The reasoning feels circular and confused, even when the output is good.

I don't find it particularly pleasant to work with as a thought partner. It's a tool I use for specific tasks, not a model I'd have extended conversations with.

---

## Best Practices

1. **Use it inside AntiGravity**: The integration is where it shines
2. **Use it for front-end**: This is its wheelhouse
3. **Use it for asset generation**: Multimodal capabilities are strong
4. **Don't read the reasoning**: Just trust the output
5. **Don't reach for it as a generalist**: Use Opus or GPT for everything else

---

## When I Reach for Gemini

Honestly? Not often. My workflow is:

1. **Need to generate images/assets?** → Gemini in AntiGravity
2. **Need strong front-end design?** → Consider Gemini
3. **Everything else?** → Opus or GPT

It's a specialist, not a daily driver.

---

## vs Other Models

| Compared To | Verdict |
|-------------|---------|
| Claude Opus 4.5 | Opus is the better generalist. Gemini has better front-end design instincts but is less versatile. |
| GPT 5.1 | Both have cleaner design aesthetics than Claude. GPT is better for analysis; Gemini for visual work. |

---

*Last updated: December 2025*
